@article{Schultz2021,
  author = {Schultz, Martin and Betancourt, Clara and Gong, Bing and Kleinert, Felix and Langguth, Michael and Leufen, Lukas and Mozaffari, Amirpasha and Stadtler, Scarlet},
  year = {2021},
  month = {02},
  title = {Can deep learning beat numerical weather prediction?},
  volume = {379},
  journal = {Philosophical Transactions of The Royal Society A Mathematical Physical and Engineering Sciences},
  doi = {10.1098/rsta.2020.0097}
}

@article{Google2023,
  author = {Remi Lam  and Alvaro Sanchez-Gonzalez  and Matthew Willson  and Peter Wirnsberger  and Meire Fortunato  and Ferran Alet  and Suman Ravuri  and Timo Ewalds  and Zach Eaton-Rosen  and Weihua Hu  and Alexander Merose  and Stephan Hoyer  and George Holland  and Oriol Vinyals  and Jacklynn Stott  and Alexander Pritzel  and Shakir Mohamed  and Peter Battaglia },
  title = {Learning skillful medium-range global weather forecasting},
  journal = {Science},
  volume = {382},
  number = {6677},
  pages = {1416-1421},
  year = {2023},
  doi = {10.1126/science.adi2336},
  URL = {https://www.science.org/doi/abs/10.1126/science.adi2336},
  eprint = {https://www.science.org/doi/pdf/10.1126/science.adi2336},
  abstract = {Global medium-range weather forecasting is critical to decision-making across many social and economic domains. Traditional numerical weather prediction uses increased compute resources to improve forecast accuracy but does not directly use historical weather data to improve the underlying model. Here, we introduce GraphCast, a machine learning?based method trained directly from reanalysis data. It predicts hundreds of weather variables for the next 10 days at 0.25Åã resolution globally in under 1 minute. GraphCast significantly outperforms the most accurate operational deterministic systems on 90\% of 1380 verification targets, and its forecasts support better severe event prediction, including tropical cyclone tracking, atmospheric rivers, and extreme temperatures. GraphCast is a key advance in accurate and efficient weather forecasting and helps realize the promise of machine learning for modeling complex dynamical systems. The numerical models used to predict weather are large, complex, and computationally demanding and do not learn from past weather patterns. Lam et al. introduced a machine learning?based method that has been trained directly from reanalysis data of past atmospheric conditions. In this way, the authors were able to quickly predict hundreds of weather variables globally up to 10 days in advance and at high resolution. Their predictions were more accurate than those of traditional weather models in 90\% of tested cases and displayed better severe event prediction for tropical cyclones, atmospheric rivers, and extreme temperatures. ?H. Jesse Smith Machine learning leads to better, faster, and cheaper weather forecasting.}
}

@article{doi:10.1146/annurev.fluid.30.1.329,
author = {Chen, Shiyi and Doolen, Gary D.},
title = {LATTICE BOLTZMANN METHOD FOR FLUID FLOWS},
journal = {Annual Review of Fluid Mechanics},
volume = {30},
number = {1},
pages = {329-364},
year = {1998},
doi = {10.1146/annurev.fluid.30.1.329},
URL = {https://doi.org/10.1146/annurev.fluid.30.1.329},
eprint = {https://doi.org/10.1146/annurev.fluid.30.1.329},
abstract = { ? Abstract?We present an overview of the lattice Boltzmann method (LBM), a parallel and efficient algorithm for simulating single-phase and multiphase fluid flows and for incorporating additional physical complexities. The LBM is especially useful for modeling complicated boundary conditions and multiphase interfaces. Recent extensions of this method are described, including simulations of fluid turbulence, suspension flows, and reaction diffusion systems. }
}

@article{Hornik1989MultilayerFN,
  title={Multilayer feedforward networks are universal approximators},
  author={Kurt Hornik and Maxwell B. Stinchcombe and Halbert L. White},
  journal={Neural Networks},
  year={1989},
  volume={2},
  pages={359-366},
  url={https://api.semanticscholar.org/CorpusID:2757547}
}

@article{Inamuro1990NumericalSO,
  author = {Inamuro, Takaji and Sturtevant, Bradford},
  title = "{Numerical study of discrete-velocity gases}",
  journal = {Physics of Fluids A: Fluid Dynamics},
  volume = {2},
  number = {12},
  pages = {2196-2203},
  year = {1990},
  month = {12},
  issn = {0899-8213},
  doi = {10.1063/1.857825},
  url = {https://doi.org/10.1063/1.857825},
  eprint = {https://pubs.aip.org/aip/pof/article-pdf/2/12/2196/12512365/2196\_1\_online.pdf},
}

@article{PhysRev.94.511,
  title = {A Model for Collision Processes in Gases. I. Small Amplitude Processes in Charged and Neutral One-Component Systems},
  author = {Bhatnagar, P. L. and Gross, E. P. and Krook, M.},
  journal = {Phys. Rev.},
  volume = {94},
  issue = {3},
  pages = {511-525},
  numpages = {0},
  year = {1954},
  month = {May},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRev.94.511},
  url = {https://link.aps.org/doi/10.1103/PhysRev.94.511}
}

@article {CHEN2021114451,
title = {2-D regional short-term wind speed forecast based on CNN-LSTM deep learning model},
journal = {Energy Conversion and Management},
volume = {244},
pages = {114451},
year = {2021},
issn = {0196-8904},
doi = {https://doi.org/10.1016/j.enconman.2021.114451},
url = {https://www.sciencedirect.com/science/article/pii/S0196890421006270},
author = {Yaoran Chen and Yan Wang and Zhikun Dong and Jie Su and Zhaolong Han and Dai Zhou and Yongsheng Zhao and Yan Bao},
keywords = {Regional wind speed prediction, CNN, LSTM, Temporal series fitness, Spatial distribution},
abstract = {Short-term wind speed forecast is of great importance to wind farm regulation and its early warning. Previous studies mainly focused on the prediction at a single location but few extended the task to 2-D wind plane. In this study, a novel deep learning model was proposed for a 2-D regional wind speed forecast, using the combination of the auto-encoder of convolutional neural network (CNN) and the long short-term memory unit (LSTM). The 12-hidden-layer deep CNN was adopted to encode the high dimensional 2-D input into the embedding vector and inversely, to decode such latent representation after it was predicted by the LSTM module based on historical data. The model performance was compared with parallel models under different criteria, including MAE, RMSE and R2, all showing stable and considerable enhancements. For instance, the overall MAE value dropped to 0.35?m/s for the current model, which is 32.7%, 28.8% and 18.9% away from the prediction results using the persistence, basic ANN and LSTM model. Moreover, comprehensive discussions were provided from both temporal and spatial views of analysis, revealing that the current model can not only offer an accurate wind speed forecast along timeline (R2 equals to 0.981), but also give a distinct estimation of the spatial wind speed distribution in 2-D wind farm.}
}

@Article {Satofuka1999,
author={Satofuka, N.
and Nishioka, T.},
title={Parallelization of lattice Boltzmann method for incompressible flow computations},
journal={Computational Mechanics},
year={1999},
month={Mar},
day={01},
volume={23},
number={2},
pages={164-171},
abstract={Parallel computation of the two and three-dimensional decaying homogeneous isotropic turbulence using the lattice Boltzmann method are presented. BGK type approximation for collision term in 9 velocity square lattice model is used. It is found that the lattice Boltzmann method is able to reproduce the dynamics of decaying turbulence and could be an alternative for solving the Navier-Stokes equations. The lattice Boltzmann method is parallelized by using domain decomposition and implemented on a distributed memory computer, Hitachi SR2201. It is found that vertical decomposition gives the highest speedup. In the case of horizontal decomposition the longer the number of lattice units in horizontal direction of each subdomain, the shorter the CPU time. Extension to three-dimension is carried out using 15 velocity cubic lattice model. Compared with the result of two-dimensional case, a higher speedup is obtained than in the three-dimensional simulation. Further investigation is needed on the accuracy and efficiency of cubic lattice BGK model.},
issn={1432-0924},
doi={10.1007/s004660050397},
url={https://doi.org/10.1007/s004660050397}
}

@article{PINNs2020,
doi:10.1126/science.aaw4741,
author = {Maziar Raissi  and Alireza Yazdani  and George Em Karniadakis },
title = {Hidden fluid mechanics: Learning velocity and pressure fields from flow visualizations},
journal = {Science},
volume = {367},
number = {6481},
pages = {1026-1030},
year = {2020},
doi = {10.1126/science.aaw4741},
URL = {https://www.science.org/doi/abs/10.1126/science.aaw4741},
eprint = {https://www.science.org/doi/pdf/10.1126/science.aaw4741},
abstract = {Quantifying fluid flow is relevant to disciplines ranging from geophysics to medicine. Flow can be experimentally visualized using, for example, smoke or contrast agents, but extracting velocity and pressure fields from this information is tricky. Raissi et al. developed a machine-learning approach to tackle this problem. Their method exploits the knowledge of Navier-Stokes equations, which govern the dynamics of fluid flow in many scientifically relevant situations. The authors illustrate their approach using examples such as blood flow in an aneurysm. Science, this issue p. 1026 A machine learning approach exploiting the knowledge of Navier-Stokes equations can extract detailed fluid flow information. For centuries, flow visualization has been the art of making fluid motion visible in physical and biological systems. Although such flow patterns can be, in principle, described by the Navier-Stokes equations, extracting the velocity and pressure fields directly from the images is challenging. We addressed this problem by developing hidden fluid mechanics (HFM), a physics-informed deep-learning framework capable of encoding the Navier-Stokes equations into the neural networks while being agnostic to the geometry or the initial and boundary conditions. We demonstrate HFM for several physical and biomedical problems by extracting quantitative information for which direct measurements may not be possible. HFM is robust to low resolution and substantial noise in the observation data, which is important for potential applications.}
}

@Inbook{Lesieur1990,
author="Lesieur, Marcel",
title="Diffusion of Passive Scalars",
bookTitle="Turbulence in Fluids: Stochastic and Numerical Modelling",
year="1990",
publisher="Springer Netherlands",
address="Dordrecht",
pages="205--241",
abstract="We have already seen that under certain approximations consisting in neglecting the buoyancy in the Boussinesq approximation derived from the Navier-Stokes equations, the temperature {\$}{\$}T{\backslash}left( {\{}{\backslash}vec x,t{\}} {\backslash}right){\$}{\$}satisfied a passive scalar type diffusion equation(VIII-1-1){\$}{\$}{\backslash}frac{\{}{\{}{\backslash}partial T{\}}{\}}{\{}{\{}{\backslash}partial t{\}}{\}} + {\backslash}vec u.{\backslash}vec {\backslash}nabla T = {\backslash}kappa {\{}{\backslash}nabla ^2{\}}T{\$}{\$}and was simply transported by the fluid particle (and diffused by molecular effects) without any action on the flow dynamics. More generally, one can consider any passive quantity which diffuses according to eq. (VIII-1-1), such as a dye which marks the flow. The Schmidt number of the passive scalar is where k is the molecular diffusivity of the scalar. It corresponds to the Prandtl number when the passive scalar is the temperature. Since we will consider only one diffusing quantity here, we will associate it with the temperature, and speak of the Prandtl number of the passive scalar.",
isbn="978-94-009-0533-7",
doi="10.1007/978-94-009-0533-7_8",
url="https://doi.org/10.1007/978-94-009-0533-7_8"
}

@Article{app13126892,
AUTHOR = {Pateras, Joseph and Rana, Pratip and Ghosh, Preetam},
TITLE = {A Taxonomic Survey of Physics-Informed Machine Learning},
JOURNAL = {Applied Sciences},
VOLUME = {13},
YEAR = {2023},
NUMBER = {12},
ARTICLE-NUMBER = {6892},
URL = {https://www.mdpi.com/2076-3417/13/12/6892},
ISSN = {2076-3417},
ABSTRACT = {Physics-informed machine learning (PIML) refers to the emerging area of extracting physically relevant solutions to complex multiscale modeling problems lacking sufficient quantity and veracity of data with learning models informed by physically relevant prior information. This work discusses the recent critical advancements in the PIML domain. Novel methods and applications of domain decomposition in physics-informed neural networks (PINNs) in particular are highlighted. Additionally, we explore recent works toward utilizing neural operator learning to intuit relationships in physics systems traditionally modeled by sets of complex governing equations and solved with expensive differentiation techniques. Finally, expansive applications of traditional physics-informed machine learning and potential limitations are discussed. In addition to summarizing recent work, we propose a novel taxonomic structure to catalog physics-informed machine learning based on how the physics-information is derived and injected into the machine learning process. The taxonomy assumes the explicit objectives of facilitating interdisciplinary collaboration in methodology, thereby promoting a wider characterization of what types of physics problems are served by the physics-informed learning machines and assisting in identifying suitable targets for future work. To summarize, the major twofold goal of this work is to summarize recent advancements and introduce a taxonomic catalog for applications of physics-informed machine learning.},
DOI = {10.3390/app13126892}
}


@book {Asakura1989,
  author = {ì˙ñ{ó¨ëÃóÕäwâÔï“},
  title = {ó¨ëÃóÕäwÉVÉäÅ[ÉY},
  publisher = {í©ëqèëìX},
  year = {1989.7-},
  URL = {https://ci.nii.ac.jp/ncid/BN03642451}
}

@book {Inamuro2020,
author = {àÓé∫ó≤ìÒ, ãgñÏê≥êl, óÈñÿçNóS íò},
title = {äiéqÉ{ÉãÉcÉ}Éìñ@ì¸ñÂ : ï°éGã´äEÇ®ÇÊÇ—à⁄ìÆã´äEó¨ÇÍÇÃêîílåvéZñ@},
publisher = {ä€ëPèoî≈},
year = {2020.1},
URL = {https://ndlsearch.ndl.go.jp/books/R100000002-I03017878}
}